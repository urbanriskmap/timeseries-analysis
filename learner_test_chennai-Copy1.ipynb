{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-23 02:11:14,216 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:11:14,216 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:11:14,218 - DEBUG - GoogleLabeler constructed\n",
      "2019-08-23 02:11:14,218 - DEBUG - GoogleLabeler constructed\n",
      "2019-08-23 02:11:14,219 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:11:14,219 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:11:14,220 - DEBUG - GoogleLabeler constructed\n",
      "2019-08-23 02:11:14,220 - DEBUG - GoogleLabeler constructed\n",
      "2019-08-23 02:11:14,221 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:11:14,221 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:11:14,223 - DEBUG - AwsLabeler constructed\n",
      "2019-08-23 02:11:14,223 - DEBUG - AwsLabeler constructed\n",
      "2019-08-23 02:11:14,224 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:11:14,224 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:11:14,225 - DEBUG - AwsLabeler constructed\n",
      "2019-08-23 02:11:14,225 - DEBUG - AwsLabeler constructed\n"
     ]
    }
   ],
   "source": [
    "from loaders.cognicity_loader import CognicityLoader\n",
    "from learners.perceptron_learner import PerceptronLearner\n",
    "from learners.svm_learner import SvmLearner\n",
    "\n",
    "import chennai_config\n",
    "config = chennai_config.config\n",
    "\n",
    "# import jakarta_config\n",
    "# config = jakarta_config.config\n",
    "\n",
    "# import chennai_only_pics_config\n",
    "# config = chennai_only_pics_config.config\n",
    "\n",
    "RERUN = True\n",
    "\n",
    "from image_recognition.goog_recog import GoogleLabeler\n",
    "#goog_learner = PerceptronLearner(config, CognicityLoader, GoogleLabeler)\n",
    "goog_learner = SvmLearner(config, CognicityLoader, GoogleLabeler)\n",
    "\n",
    "from image_recognition.aws_recog import AwsLabeler\n",
    "#aws_learner = PerceptronLearner(config, CognicityLoader, AwsLabeler)\n",
    "aws_learner = SvmLearner(config, CognicityLoader, AwsLabeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-23 02:16:57,910 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:16:57,910 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:16:57,913 - DEBUG - IdentityLabeler constructed\n",
      "2019-08-23 02:16:57,913 - DEBUG - IdentityLabeler constructed\n",
      "2019-08-23 02:16:57,914 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:16:57,914 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:16:57,915 - DEBUG - IdentityLabeler constructed\n",
      "2019-08-23 02:16:57,915 - DEBUG - IdentityLabeler constructed\n",
      "2019-08-23 02:16:57,916 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:16:57,916 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:16:57,919 - DEBUG - AwsLabeler constructed\n",
      "2019-08-23 02:16:57,919 - DEBUG - AwsLabeler constructed\n",
      "2019-08-23 02:16:57,920 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:16:57,920 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:16:57,921 - DEBUG - AwsLabeler constructed\n",
      "2019-08-23 02:16:57,921 - DEBUG - AwsLabeler constructed\n",
      "2019-08-23 02:16:57,922 - DEBUG - logging from: default_chennai_data/aws_labels_default.p\n",
      "2019-08-23 02:16:57,922 - DEBUG - logging from: default_chennai_data/aws_labels_default.p\n",
      "2019-08-23 02:16:59,084 - INFO - Num Correct 3 Out of 3\n",
      "2019-08-23 02:16:59,084 - INFO - Num Correct 3 Out of 3\n",
      "2019-08-23 02:16:59,085 - INFO - Val score: 1.0\n",
      "2019-08-23 02:16:59,085 - INFO - Val score: 1.0\n",
      "2019-08-23 02:16:59,110 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:16:59,110 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:16:59,111 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:16:59,111 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:17:00,753 - INFO - Num Correct 5 Out of 10\n",
      "2019-08-23 02:17:00,753 - INFO - Num Correct 5 Out of 10\n",
      "2019-08-23 02:17:00,756 - INFO - Val score: 0.5\n",
      "2019-08-23 02:17:00,756 - INFO - Val score: 0.5\n"
     ]
    }
   ],
   "source": [
    "from learners.identity_learner import IdentityLearner\n",
    "from flood_depth.flood_labeler import IdentityLabeler\n",
    "from image_recognition.goog_recog import GoogleLabeler\n",
    "from nlp.bow_labeler import BowLabeler\n",
    "\n",
    "identity_learner = IdentityLearner(config, CognicityLoader, IdentityLabeler)\n",
    "\n",
    "\n",
    "from learners.ensemble_learner import EnsembleLearner\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "validation_set = set(random.sample(config[\"flood_pkeys\"], 5))\n",
    "validation_set = validation_set.union(set(random.sample(config[\"no_flood_pkeys\"], 5)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# aws_learner = SvmLearner(config, CognicityLoader, AwsLabeler)\n",
    "# th, th0 = aws_learner.run_learner(\"aws_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":1000, \"print\":True})\n",
    "# \n",
    "# bow_learner = SvmLearner(config, CognicityLoader, BowLabeler)\n",
    "# th, th0 = bow_learner.run_learner(\"bow_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":400, \"print\":True})\n",
    "# \n",
    "# goog_learner = SvmLearner(config, CognicityLoader, GoogleLabeler)\n",
    "# th, th0 = goog_learner.run_learner(\"goog_separator.p\", rerun=True, validation_keys=validation_set, params={\"T\":1000, \"print\":True})\n",
    "# \n",
    "# fh_learner = IdentityLearner(config, CognicityLoader, IdentityLabeler)\n",
    "# meh = fh_learner.run_learner(\"iden_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":400, \"print\":True})\n",
    "# \n",
    "# learners = [aws_learner, goog_learner, bow_learner, fh_learner]\n",
    "# names = [\"aws.p\", \"goog.p\", \"bow.p\", \"fh.p\"]\n",
    "\n",
    "aws_learner = SvmLearner(config, CognicityLoader, AwsLabeler)\n",
    "th, th0 = aws_learner.run_learner(\"aws_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":1000, \"print\":True})\n",
    "bow_learner = SvmLearner(config, CognicityLoader, BowLabeler)\n",
    "th, th0 = bow_learner.run_learner(\"bow_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":400, \"print\":True})\n",
    "\n",
    "learners = [aws_learner, bow_learner]\n",
    "names = [\"aws.p\", \"bow.p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-23 02:33:08,662 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:08,662 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:08,664 - DEBUG - IdentityLabeler constructed\n",
      "2019-08-23 02:33:08,664 - DEBUG - IdentityLabeler constructed\n",
      "2019-08-23 02:33:08,665 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:08,665 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:08,666 - DEBUG - IdentityLabeler constructed\n",
      "2019-08-23 02:33:08,666 - DEBUG - IdentityLabeler constructed\n",
      "2019-08-23 02:33:08,667 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:08,667 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:08,668 - DEBUG - AwsLabeler constructed\n",
      "2019-08-23 02:33:08,668 - DEBUG - AwsLabeler constructed\n",
      "2019-08-23 02:33:08,670 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:08,670 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:08,671 - DEBUG - AwsLabeler constructed\n",
      "2019-08-23 02:33:08,671 - DEBUG - AwsLabeler constructed\n",
      "2019-08-23 02:33:08,671 - DEBUG - logging from: default_chennai_data/aws_labels_default.p\n",
      "2019-08-23 02:33:08,671 - DEBUG - logging from: default_chennai_data/aws_labels_default.p\n",
      "2019-08-23 02:33:09,841 - INFO - Num Correct 3 Out of 3\n",
      "2019-08-23 02:33:09,841 - INFO - Num Correct 3 Out of 3\n",
      "2019-08-23 02:33:09,842 - INFO - Val score: 1.0\n",
      "2019-08-23 02:33:09,842 - INFO - Val score: 1.0\n",
      "2019-08-23 02:33:09,865 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:09,865 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:09,866 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:09,866 - DEBUG - CognicityLoader constructed\n",
      "2019-08-23 02:33:11,504 - INFO - Num Correct 5 Out of 10\n",
      "2019-08-23 02:33:11,504 - INFO - Num Correct 5 Out of 10\n",
      "2019-08-23 02:33:11,506 - INFO - Val score: 0.5\n",
      "2019-08-23 02:33:11,506 - INFO - Val score: 0.5\n",
      "2019-08-23 02:33:11,578 - DEBUG - logging from: default_chennai_data/aws.p\n",
      "2019-08-23 02:33:11,578 - DEBUG - logging from: default_chennai_data/aws.p\n",
      "2019-08-23 02:33:11,580 - DEBUG - logging from: default_chennai_data/bow.p\n",
      "2019-08-23 02:33:11,580 - DEBUG - logging from: default_chennai_data/bow.p\n",
      "/home/abrahamq/timeseries-analysis/simple_nn.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.output(y_pred)\n",
      "/home/abrahamq/timeseries-analysis/simple_nn.py:62: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: tensor(0.7357, grad_fn=<NllLossBackward>)\n",
      "Epoch: 500\n",
      "Loss: tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1000\n",
      "Loss: tensor(0.4899, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1500\n",
      "Loss: tensor(0.4269, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2000\n",
      "Loss: tensor(0.3772, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2500\n",
      "Loss: tensor(0.3385, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3000\n",
      "Loss: tensor(0.3080, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3500\n",
      "Loss: tensor(0.2824, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4000\n",
      "Loss: tensor(0.2610, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4500\n",
      "Loss: tensor(0.2430, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5000\n",
      "Loss: tensor(0.2284, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5500\n",
      "Loss: tensor(0.2167, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6000\n",
      "Loss: tensor(0.2066, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6500\n",
      "Loss: tensor(0.1981, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7000\n",
      "Loss: tensor(0.1904, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7500\n",
      "Loss: tensor(0.1834, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8000\n",
      "Loss: tensor(0.1771, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8500\n",
      "Loss: tensor(0.1712, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9000\n",
      "Loss: tensor(0.1658, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9500\n",
      "Loss: tensor(0.1607, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10000\n",
      "Loss: tensor(0.1566, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10500\n",
      "Loss: tensor(0.1529, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11000\n",
      "Loss: tensor(0.1495, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11500\n",
      "Loss: tensor(0.1463, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12000\n",
      "Loss: tensor(0.1434, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12500\n",
      "Loss: tensor(0.1406, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13000\n",
      "Loss: tensor(0.1380, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13500\n",
      "Loss: tensor(0.1356, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14000\n",
      "Loss: tensor(0.1334, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14500\n",
      "Loss: tensor(0.1312, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15000\n",
      "Loss: tensor(0.1293, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15500\n",
      "Loss: tensor(0.1274, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16000\n",
      "Loss: tensor(0.1256, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16500\n",
      "Loss: tensor(0.1239, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17000\n",
      "Loss: tensor(0.1223, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17500\n",
      "Loss: tensor(0.1208, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18000\n",
      "Loss: tensor(0.1194, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18500\n",
      "Loss: tensor(0.1180, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19000\n",
      "Loss: tensor(0.1167, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19500\n",
      "Loss: tensor(0.1155, grad_fn=<NllLossBackward>)\n",
      "Ensemble Score:  0.7\n",
      "0.7\n",
      "COMPARE WITH SVM: \n",
      "Num Correct 9 Out of 10\n",
      "Val score: 0.9\n",
      "____________\n"
     ]
    }
   ],
   "source": [
    "from learners.identity_learner import IdentityLearner\n",
    "from learners.identity_learner import IdentityLearner\n",
    "from flood_depth.flood_labeler import IdentityLabeler\n",
    "from image_recognition.goog_recog import GoogleLabeler\n",
    "from nlp.bow_labeler import BowLabeler\n",
    "\n",
    "identity_learner = IdentityLearner(config, CognicityLoader, IdentityLabeler)\n",
    "\n",
    "\n",
    "from learners.ensemble_learner import EnsembleLearner\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# validation_set = set(random.sample(config[\"flood_pkeys\"], 15))\n",
    "# validation_set = validation_set.union(set(random.sample(config[\"no_flood_pkeys\"], 15)))\n",
    "\n",
    "# from sklearn.model_selection import ShuffleSplit\n",
    "# rs = ShuffleSplit(n_splits =5, test_size=.10)\n",
    "# \n",
    "# \n",
    "# aws_learner = SvmLearner(config, CognicityLoader, AwsLabeler)\n",
    "# th, th0 = aws_learner.run_learner(\"aws_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":1000, \"print\":True})\n",
    "# \n",
    "# bow_learner = SvmLearner(config, CognicityLoader, BowLabeler)\n",
    "# th, th0 = bow_learner.run_learner(\"bow_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":400, \"print\":True})\n",
    "# \n",
    "# goog_learner = SvmLearner(config, CognicityLoader, GoogleLabeler)\n",
    "# th, th0 = goog_learner.run_learner(\"goog_separator.p\", rerun=True, validation_keys=validation_set, params={\"T\":1000, \"print\":True})\n",
    "# \n",
    "# fh_learner = IdentityLearner(config, CognicityLoader, IdentityLabeler)\n",
    "# meh = fh_learner.run_learner(\"iden_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":400, \"print\":True})\n",
    "# \n",
    "# learners = [aws_learner, goog_learner, bow_learner, fh_learner]\n",
    "# names = [\"aws.p\", \"goog.p\", \"bow.p\", \"fh.p\"]\n",
    "# \n",
    "# \n",
    "aws_learner = SvmLearner(config, CognicityLoader, AwsLabeler)\n",
    "th, th0 = aws_learner.run_learner(\"aws_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":1000, \"print\":True})\n",
    "bow_learner = SvmLearner(config, CognicityLoader, BowLabeler)\n",
    "th, th0 = bow_learner.run_learner(\"bow_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":400, \"print\":True})\n",
    "\n",
    "learners = [aws_learner, bow_learner]\n",
    "names = [\"aws.p\", \"bow.p\"]\n",
    "# \n",
    "# fh_learner = IdentityLearner(config, CognicityLoader, IdentityLabeler)\n",
    "# meh = fh_learner.run_learner(\"iden_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":400, \"print\":True})\n",
    "\n",
    "# aws_learner = SvmLearner(config, CognicityLoader, AwsLabeler)\n",
    "# th, th0 = aws_learner.run_learner(\"aws_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":1000, \"print\":True})\n",
    "# \n",
    "# bow_learner = SvmLearner(config, CognicityLoader, BowLabeler)\n",
    "# th, th0 = bow_learner.run_learner(\"bow_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":400, \"print\":True})\n",
    "# \n",
    "# fh_learner = IdentityLearner(config, CognicityLoader, IdentityLabeler)\n",
    "# meh = fh_learner.run_learner(\"iden_separator.p\", rerun=RERUN, validation_keys=validation_set, params={\"T\":400, \"print\":True})\n",
    "# \n",
    "# learners = [aws_learner, bow_learner, fh_learner]\n",
    "# names = [\"aws.p\",  \"bow.p\", \"fh.p\"]\n",
    "\n",
    "en_learner = EnsembleLearner(config, names, learners)\n",
    "\n",
    "\n",
    "\n",
    "nn_model = en_learner.run_learner(\"chennai_en.p\", rerun=RERUN, validation_keys=validation_set, params={\"hidden\":10, \"print\":True, \"T\":5000})\n",
    "import math\n",
    "probs = math.e**en_learner.res\n",
    "probs\n",
    "import numpy as np\n",
    "p = probs.data.numpy()\n",
    "predicted = np.argmax(p, axis=1)\n",
    "val_labs = en_learner.val_labels\n",
    "true = np.where(val_labs <0, 0, 1)\n",
    "score = np.sum(predicted == true)/(true.shape[0])\n",
    "print(\"Ensemble Score: \", score)\n",
    "\n",
    "import math\n",
    "probs = math.e**en_learner.res\n",
    "probs\n",
    "\n",
    "import numpy as np\n",
    "p = probs.data.numpy()\n",
    "predicted = np.argmax(p, axis=1)\n",
    "val_labs = en_learner.val_labels\n",
    "true = np.where(val_labs <0, 0, 1)\n",
    "score = np.sum(predicted == true)/(true.shape[0])\n",
    "print(score)\n",
    "\n",
    "print(\"COMPARE WITH SVM: \")\n",
    "t_data = en_learner.train_matrix\n",
    "t_labels = en_learner.t_labels\n",
    "val_data = en_learner.val_matrix\n",
    "val_labels  = en_learner.val_labels\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=\"scale\", kernel=\"rbf\", degree=3)\n",
    "        # sklearn expects rows to be data points, we've gone with columns\n",
    "clf.fit(t_data.T, t_labels)\n",
    "\n",
    "pred = clf.predict(val_data.T)\n",
    "\n",
    "correct = np.sum(val_labels == pred)\n",
    "\n",
    "total = val_data.shape[1]\n",
    "percent_correct = correct/total\n",
    "print(\"Num Correct \" + str(correct) +\n",
    "                 \" Out of \" + str(total))\n",
    "print(\"Val score: \" + str(percent_correct))\n",
    "print(\"____________\")\n",
    "\n",
    "# mispredicted keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: tensor(0.7627, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abrahamq/timeseries-analysis/simple_nn.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.output(y_pred)\n",
      "/home/abrahamq/timeseries-analysis/simple_nn.py:62: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500\n",
      "Loss: tensor(0.6902, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1000\n",
      "Loss: tensor(0.6886, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1500\n",
      "Loss: tensor(0.6844, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2000\n",
      "Loss: tensor(0.6796, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2500\n",
      "Loss: tensor(0.6748, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3000\n",
      "Loss: tensor(0.6700, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3500\n",
      "Loss: tensor(0.6663, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4000\n",
      "Loss: tensor(0.6627, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4500\n",
      "Loss: tensor(0.6592, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5000\n",
      "Loss: tensor(0.6557, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5500\n",
      "Loss: tensor(0.6522, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6000\n",
      "Loss: tensor(0.6485, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6500\n",
      "Loss: tensor(0.6448, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7000\n",
      "Loss: tensor(0.6411, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7500\n",
      "Loss: tensor(0.6374, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8000\n",
      "Loss: tensor(0.6338, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8500\n",
      "Loss: tensor(0.6302, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9000\n",
      "Loss: tensor(0.6268, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9500\n",
      "Loss: tensor(0.6233, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10000\n",
      "Loss: tensor(0.6200, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10500\n",
      "Loss: tensor(0.6168, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11000\n",
      "Loss: tensor(0.6137, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11500\n",
      "Loss: tensor(0.6107, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12000\n",
      "Loss: tensor(0.6078, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12500\n",
      "Loss: tensor(0.6051, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13000\n",
      "Loss: tensor(0.6025, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13500\n",
      "Loss: tensor(0.6000, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14000\n",
      "Loss: tensor(0.5977, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14500\n",
      "Loss: tensor(0.5955, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15000\n",
      "Loss: tensor(0.5934, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15500\n",
      "Loss: tensor(0.5914, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16000\n",
      "Loss: tensor(0.5895, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16500\n",
      "Loss: tensor(0.5877, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17000\n",
      "Loss: tensor(0.5860, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17500\n",
      "Loss: tensor(0.5845, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18000\n",
      "Loss: tensor(0.5830, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18500\n",
      "Loss: tensor(0.5815, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19000\n",
      "Loss: tensor(0.5802, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19500\n",
      "Loss: tensor(0.5790, grad_fn=<NllLossBackward>)\n",
      "8\n",
      "0.22857142857142856\n",
      "Epoch: 0\n",
      "Loss: tensor(0.6219, grad_fn=<NllLossBackward>)\n",
      "Epoch: 500\n",
      "Loss: tensor(0.5192, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1000\n",
      "Loss: tensor(0.4721, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1500\n",
      "Loss: tensor(0.4415, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2000\n",
      "Loss: tensor(0.4166, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2500\n",
      "Loss: tensor(0.3940, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3000\n",
      "Loss: tensor(0.3723, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3500\n",
      "Loss: tensor(0.3530, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4000\n",
      "Loss: tensor(0.3349, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4500\n",
      "Loss: tensor(0.3156, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5000\n",
      "Loss: tensor(0.2970, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5500\n",
      "Loss: tensor(0.2790, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6000\n",
      "Loss: tensor(0.2644, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6500\n",
      "Loss: tensor(0.2525, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7000\n",
      "Loss: tensor(0.2419, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7500\n",
      "Loss: tensor(0.2324, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8000\n",
      "Loss: tensor(0.2239, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8500\n",
      "Loss: tensor(0.2162, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9000\n",
      "Loss: tensor(0.2091, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9500\n",
      "Loss: tensor(0.2027, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10000\n",
      "Loss: tensor(0.1967, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10500\n",
      "Loss: tensor(0.1913, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11000\n",
      "Loss: tensor(0.1862, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11500\n",
      "Loss: tensor(0.1815, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12000\n",
      "Loss: tensor(0.1771, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12500\n",
      "Loss: tensor(0.1730, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13000\n",
      "Loss: tensor(0.1692, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13500\n",
      "Loss: tensor(0.1656, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14000\n",
      "Loss: tensor(0.1623, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14500\n",
      "Loss: tensor(0.1591, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15000\n",
      "Loss: tensor(0.1561, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15500\n",
      "Loss: tensor(0.1533, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16000\n",
      "Loss: tensor(0.1506, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16500\n",
      "Loss: tensor(0.1481, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17000\n",
      "Loss: tensor(0.1457, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17500\n",
      "Loss: tensor(0.1435, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18000\n",
      "Loss: tensor(0.1414, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18500\n",
      "Loss: tensor(0.1394, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19000\n",
      "Loss: tensor(0.1375, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19500\n",
      "Loss: tensor(0.1357, grad_fn=<NllLossBackward>)\n",
      "34\n",
      "0.9714285714285714\n",
      "Epoch: 0\n",
      "Loss: tensor(0.6646, grad_fn=<NllLossBackward>)\n",
      "Epoch: 500\n",
      "Loss: tensor(0.5247, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1000\n",
      "Loss: tensor(0.4544, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1500\n",
      "Loss: tensor(0.4154, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2000\n",
      "Loss: tensor(0.3884, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2500\n",
      "Loss: tensor(0.3666, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3000\n",
      "Loss: tensor(0.3492, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3500\n",
      "Loss: tensor(0.3363, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4000\n",
      "Loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4500\n",
      "Loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5000\n",
      "Loss: tensor(0.3132, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5500\n",
      "Loss: tensor(0.3079, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6000\n",
      "Loss: tensor(0.3031, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6500\n",
      "Loss: tensor(0.2988, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7000\n",
      "Loss: tensor(0.2951, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7500\n",
      "Loss: tensor(0.2919, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8000\n",
      "Loss: tensor(0.2892, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8500\n",
      "Loss: tensor(0.2869, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9000\n",
      "Loss: tensor(0.2848, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9500\n",
      "Loss: tensor(0.2830, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10000\n",
      "Loss: tensor(0.2813, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10500\n",
      "Loss: tensor(0.2797, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11000\n",
      "Loss: tensor(0.2783, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11500\n",
      "Loss: tensor(0.2769, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12000\n",
      "Loss: tensor(0.2756, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12500\n",
      "Loss: tensor(0.2745, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13000\n",
      "Loss: tensor(0.2733, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13500\n",
      "Loss: tensor(0.2722, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14000\n",
      "Loss: tensor(0.2713, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14500\n",
      "Loss: tensor(0.2704, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15000\n",
      "Loss: tensor(0.2695, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15500\n",
      "Loss: tensor(0.2686, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16000\n",
      "Loss: tensor(0.2678, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16500\n",
      "Loss: tensor(0.2670, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17000\n",
      "Loss: tensor(0.2662, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17500\n",
      "Loss: tensor(0.2655, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18000\n",
      "Loss: tensor(0.2647, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18500\n",
      "Loss: tensor(0.2640, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19000\n",
      "Loss: tensor(0.2633, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19500\n",
      "Loss: tensor(0.2626, grad_fn=<NllLossBackward>)\n",
      "30\n",
      "0.8571428571428571\n",
      "Epoch: 0\n",
      "Loss: tensor(0.7342, grad_fn=<NllLossBackward>)\n",
      "Epoch: 500\n",
      "Loss: tensor(0.6931, grad_fn=<NllLossBackward>)\n",
      "Early stopping at epoch: 519\n",
      "8\n",
      "0.22857142857142856\n",
      "Epoch: 0\n",
      "Loss: tensor(0.6925, grad_fn=<NllLossBackward>)\n",
      "Epoch: 500\n",
      "Loss: tensor(0.5388, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1000\n",
      "Loss: tensor(0.4940, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1500\n",
      "Loss: tensor(0.4744, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2000\n",
      "Loss: tensor(0.4615, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2500\n",
      "Loss: tensor(0.4505, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3000\n",
      "Loss: tensor(0.4399, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3500\n",
      "Loss: tensor(0.4291, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4000\n",
      "Loss: tensor(0.4180, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4500\n",
      "Loss: tensor(0.4068, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5000\n",
      "Loss: tensor(0.3956, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5500\n",
      "Loss: tensor(0.3848, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6000\n",
      "Loss: tensor(0.3741, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6500\n",
      "Loss: tensor(0.3639, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7000\n",
      "Loss: tensor(0.3555, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7500\n",
      "Loss: tensor(0.3487, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8000\n",
      "Loss: tensor(0.3426, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8500\n",
      "Loss: tensor(0.3371, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9000\n",
      "Loss: tensor(0.3326, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9500\n",
      "Loss: tensor(0.3285, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10000\n",
      "Loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10500\n",
      "Loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11000\n",
      "Loss: tensor(0.3170, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11500\n",
      "Loss: tensor(0.3136, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12000\n",
      "Loss: tensor(0.3105, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12500\n",
      "Loss: tensor(0.3080, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13000\n",
      "Loss: tensor(0.3058, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13500\n",
      "Loss: tensor(0.3037, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14000\n",
      "Loss: tensor(0.3017, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14500\n",
      "Loss: tensor(0.2999, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15000\n",
      "Loss: tensor(0.2983, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15500\n",
      "Loss: tensor(0.2969, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16000\n",
      "Loss: tensor(0.2954, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16500\n",
      "Loss: tensor(0.2940, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17000\n",
      "Loss: tensor(0.2928, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17500\n",
      "Loss: tensor(0.2915, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18000\n",
      "Loss: tensor(0.2903, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18500\n",
      "Loss: tensor(0.2891, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19000\n",
      "Loss: tensor(0.2879, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19500\n",
      "Loss: tensor(0.2866, grad_fn=<NllLossBackward>)\n",
      "35\n",
      "1.0\n",
      "Epoch: 0\n",
      "Loss: tensor(0.7201, grad_fn=<NllLossBackward>)\n",
      "Epoch: 500\n",
      "Loss: tensor(0.5000, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1000\n",
      "Loss: tensor(0.4499, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1500\n",
      "Loss: tensor(0.4126, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2000\n",
      "Loss: tensor(0.3847, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2500\n",
      "Loss: tensor(0.3638, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3000\n",
      "Loss: tensor(0.3485, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3500\n",
      "Loss: tensor(0.3368, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4000\n",
      "Loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4500\n",
      "Loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5000\n",
      "Loss: tensor(0.3142, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5500\n",
      "Loss: tensor(0.3089, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6000\n",
      "Loss: tensor(0.3041, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6500\n",
      "Loss: tensor(0.3002, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7000\n",
      "Loss: tensor(0.2972, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7500\n",
      "Loss: tensor(0.2945, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8000\n",
      "Loss: tensor(0.2920, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8500\n",
      "Loss: tensor(0.2898, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9000\n",
      "Loss: tensor(0.2881, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9500\n",
      "Loss: tensor(0.2863, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10000\n",
      "Loss: tensor(0.2847, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10500\n",
      "Loss: tensor(0.2833, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11000\n",
      "Loss: tensor(0.2818, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11500\n",
      "Loss: tensor(0.2806, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12000\n",
      "Loss: tensor(0.2794, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12500\n",
      "Loss: tensor(0.2782, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13000\n",
      "Loss: tensor(0.2771, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13500\n",
      "Loss: tensor(0.2760, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14000\n",
      "Loss: tensor(0.2750, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14500\n",
      "Loss: tensor(0.2740, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15000\n",
      "Loss: tensor(0.2731, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15500\n",
      "Loss: tensor(0.2722, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16000\n",
      "Loss: tensor(0.2713, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16500\n",
      "Loss: tensor(0.2705, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17000\n",
      "Loss: tensor(0.2697, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17500\n",
      "Loss: tensor(0.2688, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18000\n",
      "Loss: tensor(0.2681, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18500\n",
      "Loss: tensor(0.2673, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19000\n",
      "Loss: tensor(0.2666, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19500\n",
      "Loss: tensor(0.2660, grad_fn=<NllLossBackward>)\n",
      "32\n",
      "0.9142857142857143\n",
      "Epoch: 0\n",
      "Loss: tensor(0.7341, grad_fn=<NllLossBackward>)\n",
      "Epoch: 500\n",
      "Loss: tensor(0.6883, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1000\n",
      "Loss: tensor(0.6836, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1500\n",
      "Loss: tensor(0.6792, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2000\n",
      "Loss: tensor(0.6749, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2500\n",
      "Loss: tensor(0.6709, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3000\n",
      "Loss: tensor(0.6669, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3500\n",
      "Loss: tensor(0.6631, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4000\n",
      "Loss: tensor(0.6594, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4500\n",
      "Loss: tensor(0.6559, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5000\n",
      "Loss: tensor(0.6524, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5500\n",
      "Loss: tensor(0.6489, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6000\n",
      "Loss: tensor(0.6456, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6500\n",
      "Loss: tensor(0.6424, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7000\n",
      "Loss: tensor(0.6392, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7500\n",
      "Loss: tensor(0.6360, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8000\n",
      "Loss: tensor(0.6330, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8500\n",
      "Loss: tensor(0.6300, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9000\n",
      "Loss: tensor(0.6270, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9500\n",
      "Loss: tensor(0.6242, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10000\n",
      "Loss: tensor(0.6213, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10500\n",
      "Loss: tensor(0.6186, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11000\n",
      "Loss: tensor(0.6159, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11500\n",
      "Loss: tensor(0.6133, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12000\n",
      "Loss: tensor(0.6108, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12500\n",
      "Loss: tensor(0.6084, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13000\n",
      "Loss: tensor(0.6060, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13500\n",
      "Loss: tensor(0.6038, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14000\n",
      "Loss: tensor(0.6016, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14500\n",
      "Loss: tensor(0.5994, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15000\n",
      "Loss: tensor(0.5974, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15500\n",
      "Loss: tensor(0.5953, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16000\n",
      "Loss: tensor(0.5934, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16500\n",
      "Loss: tensor(0.5914, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17000\n",
      "Loss: tensor(0.5895, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17500\n",
      "Loss: tensor(0.5877, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18000\n",
      "Loss: tensor(0.5859, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18500\n",
      "Loss: tensor(0.5842, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19000\n",
      "Loss: tensor(0.5826, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19500\n",
      "Loss: tensor(0.5810, grad_fn=<NllLossBackward>)\n",
      "8\n",
      "0.22857142857142856\n",
      "Epoch: 0\n",
      "Loss: tensor(0.6799, grad_fn=<NllLossBackward>)\n",
      "Epoch: 500\n",
      "Loss: tensor(0.5657, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1000\n",
      "Loss: tensor(0.5061, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1500\n",
      "Loss: tensor(0.4693, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2000\n",
      "Loss: tensor(0.4432, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2500\n",
      "Loss: tensor(0.4225, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3000\n",
      "Loss: tensor(0.4042, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3500\n",
      "Loss: tensor(0.3871, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4000\n",
      "Loss: tensor(0.3707, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4500\n",
      "Loss: tensor(0.3542, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5000\n",
      "Loss: tensor(0.3386, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5500\n",
      "Loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6000\n",
      "Loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6500\n",
      "Loss: tensor(0.3123, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7000\n",
      "Loss: tensor(0.3069, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7500\n",
      "Loss: tensor(0.2995, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8000\n",
      "Loss: tensor(0.2851, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8500\n",
      "Loss: tensor(0.2707, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9000\n",
      "Loss: tensor(0.2587, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9500\n",
      "Loss: tensor(0.2476, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10000\n",
      "Loss: tensor(0.2374, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10500\n",
      "Loss: tensor(0.2280, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11000\n",
      "Loss: tensor(0.2193, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11500\n",
      "Loss: tensor(0.2112, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12000\n",
      "Loss: tensor(0.2037, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12500\n",
      "Loss: tensor(0.1968, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13000\n",
      "Loss: tensor(0.1904, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13500\n",
      "Loss: tensor(0.1845, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14000\n",
      "Loss: tensor(0.1790, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14500\n",
      "Loss: tensor(0.1740, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15000\n",
      "Loss: tensor(0.1693, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15500\n",
      "Loss: tensor(0.1649, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16000\n",
      "Loss: tensor(0.1608, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16500\n",
      "Loss: tensor(0.1570, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17000\n",
      "Loss: tensor(0.1534, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17500\n",
      "Loss: tensor(0.1501, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18000\n",
      "Loss: tensor(0.1469, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18500\n",
      "Loss: tensor(0.1439, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19000\n",
      "Loss: tensor(0.1411, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19500\n",
      "Loss: tensor(0.1384, grad_fn=<NllLossBackward>)\n",
      "34\n",
      "0.9714285714285714\n",
      "Epoch: 0\n",
      "Loss: tensor(0.7432, grad_fn=<NllLossBackward>)\n",
      "Epoch: 500\n",
      "Loss: tensor(0.6775, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1000\n",
      "Loss: tensor(0.6022, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1500\n",
      "Loss: tensor(0.5436, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2000\n",
      "Loss: tensor(0.4946, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2500\n",
      "Loss: tensor(0.4516, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3000\n",
      "Loss: tensor(0.4124, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3500\n",
      "Loss: tensor(0.3764, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4000\n",
      "Loss: tensor(0.3437, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4500\n",
      "Loss: tensor(0.3147, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5000\n",
      "Loss: tensor(0.2900, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5500\n",
      "Loss: tensor(0.2691, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6000\n",
      "Loss: tensor(0.2513, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6500\n",
      "Loss: tensor(0.2364, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7000\n",
      "Loss: tensor(0.2237, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7500\n",
      "Loss: tensor(0.2129, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8000\n",
      "Loss: tensor(0.2037, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8500\n",
      "Loss: tensor(0.1956, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9000\n",
      "Loss: tensor(0.1884, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9500\n",
      "Loss: tensor(0.1819, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10000\n",
      "Loss: tensor(0.1760, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10500\n",
      "Loss: tensor(0.1707, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11000\n",
      "Loss: tensor(0.1658, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11500\n",
      "Loss: tensor(0.1613, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12000\n",
      "Loss: tensor(0.1572, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12500\n",
      "Loss: tensor(0.1533, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13000\n",
      "Loss: tensor(0.1498, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13500\n",
      "Loss: tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14000\n",
      "Loss: tensor(0.1435, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14500\n",
      "Loss: tensor(0.1407, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15000\n",
      "Loss: tensor(0.1380, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15500\n",
      "Loss: tensor(0.1357, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16000\n",
      "Loss: tensor(0.1335, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16500\n",
      "Loss: tensor(0.1315, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17000\n",
      "Loss: tensor(0.1296, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17500\n",
      "Loss: tensor(0.1279, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18000\n",
      "Loss: tensor(0.1262, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18500\n",
      "Loss: tensor(0.1246, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19000\n",
      "Loss: tensor(0.1231, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19500\n",
      "Loss: tensor(0.1216, grad_fn=<NllLossBackward>)\n",
      "34\n",
      "0.9714285714285714\n",
      "Epoch: 0\n",
      "Loss: tensor(0.8190, grad_fn=<NllLossBackward>)\n",
      "Epoch: 500\n",
      "Loss: tensor(0.5048, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1000\n",
      "Loss: tensor(0.4465, grad_fn=<NllLossBackward>)\n",
      "Epoch: 1500\n",
      "Loss: tensor(0.4063, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2000\n",
      "Loss: tensor(0.3733, grad_fn=<NllLossBackward>)\n",
      "Epoch: 2500\n",
      "Loss: tensor(0.3445, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3000\n",
      "Loss: tensor(0.3181, grad_fn=<NllLossBackward>)\n",
      "Epoch: 3500\n",
      "Loss: tensor(0.2944, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4000\n",
      "Loss: tensor(0.2741, grad_fn=<NllLossBackward>)\n",
      "Epoch: 4500\n",
      "Loss: tensor(0.2560, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5000\n",
      "Loss: tensor(0.2408, grad_fn=<NllLossBackward>)\n",
      "Epoch: 5500\n",
      "Loss: tensor(0.2274, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6000\n",
      "Loss: tensor(0.2156, grad_fn=<NllLossBackward>)\n",
      "Epoch: 6500\n",
      "Loss: tensor(0.2052, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7000\n",
      "Loss: tensor(0.1959, grad_fn=<NllLossBackward>)\n",
      "Epoch: 7500\n",
      "Loss: tensor(0.1874, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8000\n",
      "Loss: tensor(0.1798, grad_fn=<NllLossBackward>)\n",
      "Epoch: 8500\n",
      "Loss: tensor(0.1729, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9000\n",
      "Loss: tensor(0.1667, grad_fn=<NllLossBackward>)\n",
      "Epoch: 9500\n",
      "Loss: tensor(0.1611, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10000\n",
      "Loss: tensor(0.1560, grad_fn=<NllLossBackward>)\n",
      "Epoch: 10500\n",
      "Loss: tensor(0.1514, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11000\n",
      "Loss: tensor(0.1471, grad_fn=<NllLossBackward>)\n",
      "Epoch: 11500\n",
      "Loss: tensor(0.1432, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12000\n",
      "Loss: tensor(0.1395, grad_fn=<NllLossBackward>)\n",
      "Epoch: 12500\n",
      "Loss: tensor(0.1360, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13000\n",
      "Loss: tensor(0.1328, grad_fn=<NllLossBackward>)\n",
      "Epoch: 13500\n",
      "Loss: tensor(0.1297, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14000\n",
      "Loss: tensor(0.1269, grad_fn=<NllLossBackward>)\n",
      "Epoch: 14500\n",
      "Loss: tensor(0.1242, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15000\n",
      "Loss: tensor(0.1217, grad_fn=<NllLossBackward>)\n",
      "Epoch: 15500\n",
      "Loss: tensor(0.1192, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16000\n",
      "Loss: tensor(0.1170, grad_fn=<NllLossBackward>)\n",
      "Epoch: 16500\n",
      "Loss: tensor(0.1148, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17000\n",
      "Loss: tensor(0.1127, grad_fn=<NllLossBackward>)\n",
      "Epoch: 17500\n",
      "Loss: tensor(0.1108, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18000\n",
      "Loss: tensor(0.1089, grad_fn=<NllLossBackward>)\n",
      "Epoch: 18500\n",
      "Loss: tensor(0.1071, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19000\n",
      "Loss: tensor(0.1054, grad_fn=<NllLossBackward>)\n",
      "Epoch: 19500\n",
      "Loss: tensor(0.1037, grad_fn=<NllLossBackward>)\n",
      "33\n",
      "0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import make_scorer \n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "data = en_learner.train_matrix\n",
    "labels = en_learner.t_labels\n",
    "\n",
    "scores = []\n",
    "k = 10\n",
    "# make sure to shuffle the data!\n",
    "# cv = ShuffleSplit(n_splits=k, test_size=.10)\n",
    "cv = StratifiedShuffleSplit(n_splits=k, test_size=.10)\n",
    "# cv = LeaveOneOut()\n",
    "\n",
    "for i in range(1):\n",
    "    sum_correct = 0\n",
    "    for train_index, test_index in cv.split(data.T, labels):\n",
    "        t = data.T[train_index]\n",
    "        t_lab = labels[train_index]\n",
    "        en_learner.fit(t, t_lab)\n",
    "        \n",
    "        val = data.T[test_index]\n",
    "        val_lab = labels[test_index]\n",
    "        preds = en_learner.predict(val)\n",
    "        \n",
    "        num_correct = np.sum(val_lab == preds)\n",
    "        print(num_correct)\n",
    "        print(num_correct/preds.shape[0])\n",
    "        sum_correct += num_correct\n",
    "        \n",
    "    scores.append(sum_correct)\n",
    "\n",
    "# scores = cross_val_score(en_learner, data.T, labels.T, cv=cv, scoring=make_scorer(f1_score))\n",
    "# print(scores.mean(), scores.std())\n",
    "# scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7441860465116279"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_correct/data.shape[1]\n",
    "# for just aws and bow: \n",
    "# jakarta, k-10: 0.7477231329690346\n",
    "# jakarta, k-10: 0.73\n",
    "# jakarta, k-10: 0.82\n",
    "\n",
    "# for goog,aws, bow, depth\n",
    "# jakarta: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# print(en_learner.val_matrix)\n",
    "# print(en_learner.val_matrix[-1,:])\n",
    "# print(predicted)\n",
    "# np.sum(np.sum(en_learner.train_matrix[1:-1,:], axis=0) == 0)\n",
    "val_matrix = en_learner.val_matrix\n",
    "label_matrix = en_learner.val_labels\n",
    "\n",
    "\n",
    "into_sk = val_matrix.T\n",
    "print(into_sk.shape)\n",
    "into_torch = torch.from_numpy(into_sk).float()\n",
    "\n",
    "en_learner.predict(en_learner.val_matrix.T)\n",
    "\n",
    "# from simple_nn import Simple_nn\n",
    "# \n",
    "# nn = Simple_nn(into_sk.shape[1], 10)\n",
    "# nn.forward(into_torch)\n",
    "# \n",
    "# toy = EnsembleLearner(config, [3, 3], [3, 3])\n",
    "# \n",
    "# \n",
    "# print(into_sk.shape)\n",
    "# print(into_torch.size)\n",
    "# toy.fit(into_sk, label_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = en_learner.train_matrix\n",
    "t_labels = en_learner.t_labels\n",
    "val_data = en_learner.val_matrix\n",
    "val_labels  = en_learner.val_labels\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=\"scale\", kernel=\"poly\", degree=3)\n",
    "        # sklearn expects rows to be data points, we've gone with columns\n",
    "clf.fit(t_data.T, t_labels)\n",
    "\n",
    "pred = clf.predict(val_data.T)\n",
    "\n",
    "correct = np.sum(val_labels == pred)\n",
    "\n",
    "total = val_data.shape[1]\n",
    "percent_correct = correct/total\n",
    "print(\"Num Correct \" + str(correct) +\n",
    "                 \" Out of \" + str(total))\n",
    "print(\"Val score: \" + str(percent_correct))\n",
    "print(pred)\n",
    "print(val_labels)\n",
    "t_data[:,2:5]\n",
    "\n",
    "len(config[\"flood_pkeys\"])/len(config[\"all_pkeys\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_pkeys = goog_learner.val_data_w_pkey[0, (predicted != true)[0,:]]\n",
    "\n",
    "import pandas as pd\n",
    "start_known_flood = \"'2017-11-01 00:00:35.630000-04:00'\" \n",
    "end_known_flood = \"'2019-11-07 00:00:35.630000-04:00'\"\n",
    "\n",
    "chennai_all_data = pd.read_sql_query('''\n",
    "    SELECT pkey, created_at, text, disaster_type, report_data, tags, image_url FROM riskmap.all_reports \n",
    "''', params={\"start_date\": start_known_flood, \"end_date\": end_known_flood}, con=config[\"database_engine\"], index_col=\"pkey\")\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "chennai_all_data.loc[pd.Index(wrong_pkeys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = list(range(1, 7))\n",
    "a.extend([7 for i in range(10)])\n",
    "a\n",
    "diff = a[-1] - a[0]\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.pop(0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted\n",
    "\n",
    "validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "a = np.array([[1, 2, 4, 65, 75],\n",
    "         [113, 222, 4444, 65455, 7777]])\n",
    "\n",
    "b = np.array([[1, 2, 4, 65, 70, 75]])\n",
    "\n",
    "c = np.vstack((b, np.zeros((1, b.shape[1]))))\n",
    "\n",
    "b_df = pd.Index(b.T)\n",
    "\n",
    "c_df = pd.DataFrame(c.T, columns=[\"pkey\", \"data\"])\n",
    "\n",
    "a_df = pd.DataFrame(a.T, columns=[\"pkey\", \"data\"] )\n",
    "\n",
    "c_df[\"pkey\"] == a_df[\"pkey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "a = np.array([[1, 2, 4, 65, 75],\n",
    "         [113, 222, 4444, 65455, 7777]])\n",
    "\n",
    "labs = np.array([[1, 1, 1, -1, -1]])\n",
    "b = np.array([[1, 2, 4, 65, 70, 75]])\n",
    "\n",
    "c = np.vstack((b, np.zeros((1, b.shape[1]))))\n",
    "\n",
    "b_df = pd.Index(b.T)\n",
    "\n",
    "c_df = pd.DataFrame(c.T, columns=[\"pkey\", \"data\"]).set_index(\"pkey\", drop=False)\n",
    "\n",
    "a_df = pd.DataFrame(a.T, columns=[\"pkey\", \"data\"] )\n",
    "# a_df.rename_axis( \"pkey\")\n",
    "a_df.set_index(\"pkey\", inplace=True, drop=False)\n",
    "a_df\n",
    "\n",
    "# c_df.loc[a_df.index] = a_df[\"data\"]\n",
    "c_df.loc[a_df.index] = a_df.loc[a_df.index]\n",
    "eh = c_df.to_numpy()\n",
    "print(eh)\n",
    "eh[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chennai_config\n",
    "config = chennai_config.config\n",
    "def _fill_no_data_spots(data_list, label_list):\n",
    "    all_pkeys = set([1, 2, 4, 65, 70, 75]) # config[\"all_pkeys\"]\n",
    "    res = pd.DataFrame(all_pkeys, columns=[\"pkey\"]).set_index(\"pkey\", drop=False).sort_index()\n",
    "    for i, (data, labels) in enumerate(zip(data_list, label_list)):\n",
    "        add_df = pd.DataFrame(data.T, columns=[\"pkey\", i]).set_index(\"pkey\")\n",
    "        res = res.join(add_df).fillna(0)\n",
    "        # res.loc[add_df.index][i] = add_df.loc[a_df.index][i]\n",
    "        print(add_df.loc[a_df.index][i])\n",
    "        \n",
    "    flood = pd.Index([1, 2, 4])\n",
    "    no_flood = pd.Index([65, 70, 75])\n",
    "    # add in the label data as the last row\n",
    "    res.loc[flood, \"label\"] = 1\n",
    "    res.loc[no_flood, \"label\"] = -1\n",
    "    ahhh = res.to_numpy().T\n",
    "    # TODO there's probably some issue with floating point equality on the pkeys here... \n",
    "    return ahhh\n",
    "\n",
    "_fill_no_data_spots([a, a], [labs, labs] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_python",
   "language": "python",
   "name": "_python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
